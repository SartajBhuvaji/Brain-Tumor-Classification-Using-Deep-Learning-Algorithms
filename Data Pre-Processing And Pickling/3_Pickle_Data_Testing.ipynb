{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pickle-Data-Testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBge6NtfRtSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9wqZ6k7R4g-",
        "colab_type": "code",
        "outputId": "3df76f35-4560-41b9-b327-a4df85bbdc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name !='/device:GPU:0':\n",
        "  raise SystemError(\"Gpu not\")\n",
        "print('Gpu found at {} '.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gpu found at /device:GPU:0 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPOVng36R672",
        "colab_type": "code",
        "outputId": "45273c5d-0f35-4d07-ac9e-8de124dcae5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAFsfaTfSFZM",
        "colab_type": "code",
        "outputId": "162a4437-312c-467a-9a68-9346e11b9c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/Ankita n mine/BE Project/Final_Dataset\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Ankita n mine/BE Project/Final_Dataset\n",
            "Testing  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvbGqAZKS2C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_DIR = '/content/gdrive/My Drive/Ankita n mine/BE Project/Final_Dataset/Testing' # test data folder\n",
        "TRAIN_DIR = '/content/gdrive/My Drive/Ankita n mine/BE Project/Final_Dataset/Training' # train data folder\n",
        "IMG_SIZE = 150 # image size\n",
        "CATEGORIES = [\"glioma\",\"meningioma\",\"no_tumor\",\"pituitary\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV1TkxmaTXAW",
        "colab_type": "code",
        "outputId": "0cc729d9-b02a-4dcd-da76-53d8e47c18c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "testing_data = []\n",
        "\n",
        "def create_testing_data():\n",
        "    for category in CATEGORIES: \n",
        "\n",
        "        path = os.path.join(TEST_DIR,category)  # create path \n",
        "        class_num = CATEGORIES.index(category)  # get the classification  \n",
        "\n",
        "        for img in tqdm(os.listdir(path)): \n",
        "          # iterate over each image per dogs and cats \n",
        "          img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR)  # convert to array\n",
        "          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "          testing_data.append([new_array, class_num])  # add this to our training_data\n",
        "    \n",
        "    random.shuffle(testing_data)\n",
        "   # np.save('test_data.npy', testing_data)        \n",
        "\n",
        "create_testing_data()\n",
        "np.save('test_data.npy', testing_data) \n",
        "print(len(testing_data))\n",
        "\n",
        "print(\"train\")\n",
        "print()\n",
        "X_test = np.array([i[0] for i in testing_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "Y_test = [i[1] for i in testing_data]\n",
        "\n",
        "import pickle\n",
        "\n",
        "pickle_out = open(\"X_test.pickle\",\"wb\")\n",
        "pickle.dump(X_test, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"Y_test.pickle\",\"wb\")\n",
        "pickle.dump(Y_test, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3510/3510 [46:44<00:00,  1.25it/s]\n",
            "100%|██████████| 3500/3500 [37:22<00:00,  1.56it/s]\n",
            "100%|██████████| 3800/3800 [33:57<00:00,  1.87it/s]\n",
            "100%|██████████| 3510/3510 [32:05<00:00,  1.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14320\n",
            "train\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}